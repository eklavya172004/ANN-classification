{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96711c00",
      "metadata": {
        "id": "96711c00"
      },
      "outputs": [],
      "source": [
        "# Install required packages first\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = ['tensorflow', 'scikeras']\n",
        "for package in packages:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "print(\"✓ Packages installed successfully!\\n\")\n",
        "\n",
        "# Now import all required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee039f3",
      "metadata": {
        "id": "5ee039f3"
      },
      "outputs": [],
      "source": [
        "# Check if running on Google Colab and handle file upload\n",
        "try:\n",
        "    from google.colab import files\n",
        "    COLAB = True\n",
        "    print(\"✓ Running on Google Colab with GPU support!\")\n",
        "except ImportError:\n",
        "    COLAB = False\n",
        "    print(\"✓ Running locally\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a6a4211",
      "metadata": {
        "id": "5a6a4211"
      },
      "outputs": [],
      "source": [
        "# For Google Colab: Upload CSV file\n",
        "if COLAB:\n",
        "    print(\"Upload your Churn_Modelling.csv file:\")\n",
        "    uploaded = files.upload()\n",
        "    csv_file = list(uploaded.keys())[0]\n",
        "    print(f\"Uploaded: {csv_file}\")\n",
        "else:\n",
        "    csv_file = 'Churn_Modelling.csv'\n",
        "    print(f\"Using local file: {csv_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec3fff9a",
      "metadata": {
        "id": "ec3fff9a",
        "outputId": "5e326984-0737-43a1-f6dc-5428b26b62b0"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      2\u001b[39m files.upload()  \u001b[38;5;66;03m# Upload CSV\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "data=data.drop(['RowNumber','CustomerId','Surname'],axis=1)\n",
        "\n",
        "label_encode_gender=LabelEncoder()\n",
        "data['Gender'] = label_encode_gender.fit_transform(data['Gender'])\n",
        "\n",
        "one_hot_encoder_geo=OneHotEncoder(handle_unknown='ignore')\n",
        "geo_encoder = one_hot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
        "\n",
        "geo_encoder_df=pd.DataFrame(geo_encoder,columns=one_hot_encoder_geo.get_feature_names_out(['Geography']))\n",
        "\n",
        "data=pd.concat([data.drop('Geography',axis=1),geo_encoder_df],axis=1)\n",
        "\n",
        "X = data.drop('Exited', axis=1)\n",
        "y = data['Exited']\n",
        "\n",
        "print(f\"Data loaded successfully! Shape: {data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdb6bbca",
      "metadata": {
        "id": "fdb6bbca"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scalar = StandardScaler()\n",
        "X_train = scalar.fit_transform(X_train)\n",
        "X_test = scalar.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a626fdc",
      "metadata": {
        "id": "7a626fdc",
        "outputId": "1506510e-f510-487a-c82e-a22e5c0c3d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved: label_encode_gender.pkl\n",
            "✓ Saved: one_hot_encoder_geo.pkl\n",
            "✓ Saved: scalar.pkl\n",
            "\n",
            "All preprocessing objects saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Save preprocessing objects as pickle files\n",
        "with open('label_encode_gender.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encode_gender, f)\n",
        "print(\"✓ Saved: label_encode_gender.pkl\")\n",
        "\n",
        "with open('one_hot_encoder_geo.pkl', 'wb') as f:\n",
        "    pickle.dump(one_hot_encoder_geo, f)\n",
        "print(\"✓ Saved: one_hot_encoder_geo.pkl\")\n",
        "\n",
        "with open('scalar.pkl', 'wb') as f:\n",
        "    pickle.dump(scalar, f)\n",
        "print(\"✓ Saved: scalar.pkl\")\n",
        "\n",
        "print(\"\\nAll preprocessing objects saved successfully!\")\n",
        "\n",
        "# Download pickle files if on Colab\n",
        "if COLAB:\n",
        "    print(\"\\nDownloading pickle files...\")\n",
        "    files.download('label_encode_gender.pkl')\n",
        "    files.download('one_hot_encoder_geo.pkl')\n",
        "    files.download('scalar.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae01dc4",
      "metadata": {
        "id": "fae01dc4"
      },
      "outputs": [],
      "source": [
        "# Defining a function to create model and try different parameters (KerasClassifier)\n",
        "\n",
        "def create_model(neurons=32, layers=1):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "\n",
        "    for _ in range(layers - 1):\n",
        "        model.add(Dense(neurons, activation='relu'))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e085c0fd",
      "metadata": {
        "id": "e085c0fd"
      },
      "outputs": [],
      "source": [
        "# Create KerasClassifier with the model builder function\n",
        "model = KerasClassifier(model=create_model, epochs=50, batch_size=10, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2312efc",
      "metadata": {
        "id": "f2312efc"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters to test\n",
        "hyperparameters = [\n",
        "    {'epochs': 50, 'batch_size': 10},\n",
        "    {'epochs': 50, 'batch_size': 20},\n",
        "    {'epochs': 100, 'batch_size': 10},\n",
        "    {'epochs': 100, 'batch_size': 20},\n",
        "]\n",
        "\n",
        "print(f\"Testing {len(hyperparameters)} configurations...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ea9c198f",
      "metadata": {
        "id": "ea9c198f",
        "outputId": "10130d28-f736-46d0-b807-64e664200e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'hyperparameters' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1002672759.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_model_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[{i}/{len(hyperparameters)}] Training with epochs={params['epochs']}, batch_size={params['batch_size']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hyperparameters' is not defined"
          ]
        }
      ],
      "source": [
        "# Manual hyperparameter tuning (avoids scikeras/sklearn compatibility issues)\n",
        "results = []\n",
        "best_score = 0\n",
        "best_params = None\n",
        "best_model_obj = None\n",
        "\n",
        "for i, params in enumerate(hyperparameters, 1):\n",
        "    print(f\"[{i}/{len(hyperparameters)}] Training with epochs={params['epochs']}, batch_size={params['batch_size']}\")\n",
        "\n",
        "    # Create fresh model for each configuration\n",
        "    model = KerasClassifier(model=create_model, epochs=params['epochs'],\n",
        "                           batch_size=params['batch_size'], verbose=0)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    score = model.score(X_test, y_test)\n",
        "    results.append({'params': params, 'score': score})\n",
        "\n",
        "    print(f\"   Test Accuracy: {score:.4f}\\n\")\n",
        "\n",
        "    # Track best model\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_params = params\n",
        "        best_model_obj = model\n",
        "\n",
        "# Print summary\n",
        "print(\"=\"*50)\n",
        "print(\"HYPERPARAMETER TUNING RESULTS\")\n",
        "print(\"=\"*50)\n",
        "for r in results:\n",
        "    print(f\"Epochs: {r['params']['epochs']}, Batch Size: {r['params']['batch_size']} → Accuracy: {r['score']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"Best Score: {best_score:.4f}\")\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75562de8",
      "metadata": {
        "id": "75562de8"
      },
      "outputs": [],
      "source": [
        "# Save the best model\n",
        "print(\"\\nSaving the best model...\")\n",
        "best_model_obj.model_.save('churn_model_best.h5')\n",
        "print(\"✓ Model saved as: churn_model_best.h5\")\n",
        "\n",
        "# Also save model summary\n",
        "print(\"\\nBest Model Summary:\")\n",
        "best_model_obj.model_.summary()\n",
        "\n",
        "# Download model if on Colab\n",
        "if COLAB:\n",
        "    print(\"\\nDownloading model...\")\n",
        "    files.download('churn_model_best.h5')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}